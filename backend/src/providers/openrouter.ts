import { debugLog, debugToken, debugApi, debugSuccess, debugError } from "../utils/debug";

type ChatMessage = { role: "system" | "user" | "assistant"; content: string };

function mustApiKey() {
  const apiKey = process.env.OPENROUTER_API_KEY || "";
  if (!apiKey) {
    const err: any = new Error("æœªé…ç½® OPENROUTER_API_KEY");
    err.statusCode = 500;
    err.code = "OPENROUTER_KEY_MISSING";
    throw err;
  }
  return apiKey;
}

function commonHeaders() {
  const apiKey = mustApiKey();
  return {
    Authorization: `Bearer ${apiKey}`,
    "Content-Type": "application/json",
    "HTTP-Referer": process.env.OPENROUTER_HTTP_REFERER || "http://localhost",
    "X-Title": process.env.OPENROUTER_APP_TITLE || "ai-chat-webui",
  };
}

// éæµå¼ï¼ˆä½ å·²ç»ç”¨ä¸Šäº†ï¼‰
export async function openRouterChatComplete(params: {
  model: string;
  messages: ChatMessage[];
  signal?: AbortSignal;
}) {
  const res = await fetch("https://api.x1zx.com/api/v1/chat/completions", {
    method: "POST",
    headers: commonHeaders(),
    body: JSON.stringify({
      model: params.model,
      messages: params.messages,
      stream: false,
    }),
    signal: params.signal,
  });

  const text = await res.text();
  let data: any = null;
  try {
    data = text ? JSON.parse(text) : null;
  } catch {}

  // è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”æ•°æ®
  debugApi("OpenRouter å®Œæ•´å“åº”æ•°æ®", data, { prefix: "ğŸ”" });

  if (!res.ok) {
    const msg =
      data?.error?.message || data?.message || `OpenRouter è¯·æ±‚å¤±è´¥ (${res.status})`;
    const err: any = new Error(msg);
    err.statusCode = res.status;
    err.code = "OPENROUTER_ERROR";
    err.details = data;
    throw err;
  }

  const content = data?.choices?.[0]?.message?.content ?? "";
  const usage = data?.usage || {};
  
  // è°ƒè¯•ï¼šè¯¦ç»†æ‰“å°usageä¿¡æ¯
  debugToken("æå–çš„usageæ•°æ®", usage);
  debugToken("prompt_tokens", usage.prompt_tokens);
  debugToken("completion_tokens", usage.completion_tokens);
  debugToken("total_tokens", usage.total_tokens);
  
  // è®¡ç®—è´¹ç”¨ï¼ˆåŸºäºOpenRouterçš„å®šä»·ï¼‰
  const cost = calculateCost(params.model, usage);
  
  // è°ƒè¯•ï¼šæ‰“å°è®¡ç®—å‡ºçš„è´¹ç”¨
  debugToken("è®¡ç®—å‡ºçš„è´¹ç”¨", cost, { prefix: "ğŸ’°" });
  
  return { 
    content, 
    raw: data,
    usage: {
      promptTokens: usage.prompt_tokens || 0,
      completionTokens: usage.completion_tokens || 0, 
      totalTokens: usage.total_tokens || 0,
      cost
    }
  };
}

// æµå¼ï¼šè¿”å› Responseï¼Œè®© route å»è¯» res.body
export async function openRouterChatStream(params: {
  model: string;
  messages: ChatMessage[];
  signal?: AbortSignal;
}) {
  const res = await fetch("https://api.x1zx.com/api/v1/chat/completions", {
    method: "POST",
    headers: commonHeaders(),
    body: JSON.stringify({
      model: params.model,
      messages: params.messages,
      stream: true,
    }),
    signal: params.signal,
  });

  return res;
}

// è´¹ç”¨è®¡ç®—å‡½æ•°
function calculateCost(model: string, usage: any): number {
  const pricing = getModelPricing(model);
  if (!pricing) return 0;
  
  const promptCost = (usage.prompt_tokens || 0) * pricing.prompt / 1_000_000;
  const completionCost = (usage.completion_tokens || 0) * pricing.completion / 1_000_000;
  
  return promptCost + completionCost;
}

// è·å–æ¨¡å‹å®šä»·ä¿¡æ¯
function getModelPricing(modelId: string) {
  // è¿™é‡Œå¯ä»¥ä»æ•°æ®åº“æˆ–é…ç½®ä¸­è·å–å…·ä½“æ¨¡å‹çš„å®šä»·
  // ç¤ºä¾‹å®šä»·ï¼ˆéœ€è¦æ ¹æ®å®é™…OpenRouter APIè·å–æœ€æ–°ä»·æ ¼ï¼‰
  const pricingMap: { [key: string]: { prompt: number; completion: number } } = {
    "openai/gpt-4o-mini": { prompt: 0.15, completion: 0.60 },  // $0.15/1M prompt, $0.60/1M completion
    "openai/gpt-4o": { prompt: 5.00, completion: 15.00 },
    "anthropic/claude-3.5-sonnet": { prompt: 3.00, completion: 15.00 },
    "anthropic/claude-3-haiku": { prompt: 0.25, completion: 1.25 },
    "meta-llama/llama-3.1-70b-instruct": { prompt: 0.90, completion: 0.90 },
    "meta-llama/llama-3.1-8b-instruct": { prompt: 0.10, completion: 0.10 },
    // æ›´å¤šæ¨¡å‹å®šä»·...
  };
  return pricingMap[modelId];
}